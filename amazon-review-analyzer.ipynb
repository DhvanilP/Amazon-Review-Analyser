{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier, SklearnClassifier\n",
    "import csv\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division #To avoid integer division\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_set.csv\", low_memory=False)\n",
    "data = data[['reviews.rating', 'reviews.text']]\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pos_rev = []\n",
    "# pos_rev_date = []\n",
    "neg_rev = []\n",
    "# neg_rev_date = []\n",
    "neut_rev = []\n",
    "# neut_rev_date = []\n",
    "\n",
    "train['reviews.rating'] = pd.to_numeric(train['reviews.rating'], errors='coerce')\n",
    "train = train.dropna(subset=['reviews.rating'])\n",
    "train['reviews.rating'] = train['reviews.rating'].astype(int)\n",
    "\n",
    "# a = 0\n",
    "for col, row in train.iterrows():\n",
    "    if int(row[\"reviews.rating\"]) > 3:\n",
    "        pos_rev.append(row[\"reviews.text\"])\n",
    "#         pos_rev_date.append(row[\"reviews.date\"])\n",
    "    elif int(row[\"reviews.rating\"]) < 3:\n",
    "        neg_rev.append(row[\"reviews.text\"])\n",
    "#         neg_rev_date.append(row[\"reviews.date\"])\n",
    "    else:\n",
    "        neut_rev.append(row[\"reviews.text\"])\n",
    "#         neut_rev_date.append(row[\"reviews.date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split(data):    \n",
    "    data_new = []\n",
    "    for word in data:\n",
    "        try:\n",
    "            word_filter = [i.lower() for i in word.split()]\n",
    "            data_new.append(word_filter)\n",
    "        except:\n",
    "            print (' ')\n",
    "    return data_new\n",
    " \n",
    "def word_split_sentiment(data):\n",
    "    data_new = []\n",
    "    for (word, sentiment) in data:\n",
    "        try:\n",
    "            word_filter = [i.lower() for i in word.split()]\n",
    "            data_new.append((word_filter, sentiment))\n",
    "        except:\n",
    "            print (' ')\n",
    "    return data_new\n",
    "    \n",
    "def word_feats(words):    \n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import *\n",
    "\n",
    "def evaluate_classifier(featx):\n",
    "    \n",
    "    negfeats = [(featx(f), 'neg') for f in word_split(neg_rev)]\n",
    "    posfeats = [(featx(f), 'pos') for f in word_split(pos_rev)]\n",
    "    neutfeats = [(featx(f), 'neut') for f in word_split(neut_rev)]\n",
    "    \n",
    "#     print (posfeats)\n",
    "        \n",
    "    negcutoff = int(len(negfeats)*3/4)\n",
    "    poscutoff = int(len(posfeats)*3/4)\n",
    "    neutcutoff = int(len(neutfeats)*3/4)\n",
    "    \n",
    "#     print (len(posfeats))\n",
    "#     print (len(negfeats))\n",
    "#     print (len(neutfeats))\n",
    "    \n",
    "    trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff] + neutfeats[:neutcutoff]\n",
    "    testfeats = negfeats[negcutoff:] + posfeats[poscutoff:] + neutfeats[neutcutoff:]\n",
    "    \n",
    "    # using 3 classifiers\n",
    "    classifier_list = ['nb', 'maxent', 'svm']\n",
    "        \n",
    "    for cl in classifier_list:\n",
    "        if cl == 'maxent':\n",
    "            classifierName = 'Maximum Entropy'\n",
    "            classifier = MaxentClassifier.train(trainfeats, 'GIS', trace=0, encoding=None, labels=None, gaussian_prior_sigma=0, max_iter = 1)\n",
    "        elif cl == 'svm':\n",
    "            classifierName = 'SVM'\n",
    "            classifier = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "            classifier.train(trainfeats)\n",
    "        else:\n",
    "            classifierName = 'Naive Bayes'\n",
    "            classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "            \n",
    "        refsets = collections.defaultdict(set)\n",
    "        testsets = collections.defaultdict(set)\n",
    " \n",
    "        for i, (feats, label) in enumerate(testfeats):\n",
    "                refsets[label].add(i)\n",
    "                observed = classifier.classify(feats)\n",
    "                testsets[observed].add(i)\n",
    "\n",
    "        accuracy = nltk.classify.util.accuracy(classifier, testfeats)\n",
    "        pos_precision = precision(refsets['pos'], testsets['pos'])\n",
    "        pos_recall = recall(refsets['pos'], testsets['pos'])\n",
    "        pos_fmeasure = f_measure(refsets['pos'], testsets['pos'])\n",
    "        neg_precision = precision(refsets['neg'], testsets['neg'])\n",
    "        neg_recall = recall(refsets['neg'], testsets['neg'])\n",
    "        neg_fmeasure = f_measure(refsets['neg'], testsets['neg'])\n",
    "        neut_precision = precision(refsets['neut'], testsets['neut'])\n",
    "        neut_recall = recall(refsets['neut'], testsets['neut'])\n",
    "        neut_fmeasure = f_measure(refsets['neut'], testsets['neut'])\n",
    "        \n",
    "        if pos_precision is None:\n",
    "            pos_precision = 0\n",
    "        if pos_recall is None:\n",
    "            pos_recall = 0\n",
    "        if pos_fmeasure is None:\n",
    "            pos_fmeasure = 0\n",
    "        if neg_precision is None:\n",
    "            neg_precision = 0\n",
    "        if neg_recall is None:\n",
    "            neg_recall = 0\n",
    "        if neg_fmeasure is None:\n",
    "            neg_fmeasure = 0\n",
    "        if neut_precision is None:\n",
    "            neut_precision = 0\n",
    "        if neut_recall is None:\n",
    "            neut_recall = 0\n",
    "        if neut_fmeasure is None:\n",
    "            neut_fmeasure = 0\n",
    "        \n",
    "        print (' ')\n",
    "        print ('---------------------------------------')\n",
    "        print ('SINGLE FOLD RESULT ' + '(' + classifierName + ')')\n",
    "        print ('---------------------------------------')\n",
    "        print ('accuracy:', accuracy)\n",
    "        print ('precision', (pos_precision + neg_precision + neut_precision) / 3)\n",
    "        print ('recall', (pos_recall + neg_recall + neut_recall) / 3)\n",
    "        print ('f-measure', (pos_fmeasure + neg_fmeasure + neut_fmeasure) / 3)\n",
    "                \n",
    "        #classifier.show_most_informative_features()\n",
    "        \n",
    "    trainfeats = negfeats + posfeats + neutfeats\n",
    "    \n",
    "    # SHUFFLE TRAIN SET\n",
    "    # As in cross validation, the test chunk might have only negative or only positive data    \n",
    "    random.shuffle(trainfeats)    \n",
    "    n = 5 # 5-fold cross-validation    \n",
    "    \n",
    "    for cl in classifier_list:\n",
    "        \n",
    "        subset_size = int(len(trainfeats) / n)\n",
    "        accuracy = []\n",
    "        pos_precision = []\n",
    "        pos_recall = []\n",
    "        neg_precision = []\n",
    "        neg_recall = []\n",
    "        pos_fmeasure = []\n",
    "        neg_fmeasure = []\n",
    "        neut_precision = []\n",
    "        neut_recall = []\n",
    "        neut_fmeasure = []\n",
    "        cv_count = 1\n",
    "        for i in range(n):        \n",
    "            testing_this_round = trainfeats[i*subset_size:][:subset_size]\n",
    "            training_this_round = trainfeats[:i*subset_size] + trainfeats[(i+1)*subset_size:]\n",
    "            \n",
    "            if cl == 'maxent':\n",
    "                classifierName = 'Maximum Entropy'\n",
    "                classifier = MaxentClassifier.train(training_this_round, 'GIS', trace=0, encoding=None, labels=None, gaussian_prior_sigma=0, max_iter = 1)\n",
    "            elif cl == 'svm':\n",
    "                classifierName = 'SVM'\n",
    "                classifier = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "                classifier.train(training_this_round)\n",
    "            else:\n",
    "                classifierName = 'Naive Bayes'\n",
    "                classifier = NaiveBayesClassifier.train(training_this_round)\n",
    "                    \n",
    "            refsets = collections.defaultdict(set)\n",
    "            testsets = collections.defaultdict(set)\n",
    "            for i, (feats, label) in enumerate(testing_this_round):\n",
    "                refsets[label].add(i)\n",
    "                observed = classifier.classify(feats)\n",
    "                testsets[observed].add(i)\n",
    "            \n",
    "            cv_accuracy = 0\n",
    "            cv_pos_precision = 0\n",
    "            cv_pos_recall = 0\n",
    "            cv_pos_fmeasure = 0\n",
    "            cv_neg_precision = 0\n",
    "            cv_neg_recall = 0\n",
    "            cv_neg_fmeasure = 0\n",
    "            cv_neut_precision = 0\n",
    "            cv_neut_recall = 0\n",
    "            cv_neut_fmeasure = 0\n",
    "            \n",
    "            cv_accuracy = nltk.classify.util.accuracy(classifier, testing_this_round)\n",
    "            cv_pos_precision = precision(refsets['pos'], testsets['pos'])\n",
    "            cv_pos_recall = recall(refsets['pos'], testsets['pos'])\n",
    "            cv_pos_fmeasure = f_measure(refsets['pos'], testsets['pos'])\n",
    "            cv_neg_precision = precision(refsets['neg'], testsets['neg'])\n",
    "            cv_neg_recall = recall(refsets['neg'], testsets['neg'])\n",
    "            cv_neg_fmeasure = f_measure(refsets['neg'], testsets['neg'])\n",
    "            cv_neut_precision = precision(refsets['neut'], testsets['neut'])\n",
    "            cv_neut_recall = recall(refsets['neut'], testsets['neut'])\n",
    "            cv_neut_fmeasure = f_measure(refsets['neut'], testsets['neut'])\n",
    "            \n",
    "            if cv_pos_precision is None:\n",
    "                cv_pos_precision = 0\n",
    "            if cv_pos_recall is None:\n",
    "                cv_pos_recall = 0\n",
    "            if cv_pos_fmeasure is None:\n",
    "                cv_pos_fmeasure = 0\n",
    "            if cv_neg_precision is None:\n",
    "                cv_neg_precision = 0\n",
    "            if cv_neg_recall is None:\n",
    "                cv_neg_recall = 0\n",
    "            if cv_neg_fmeasure is None:\n",
    "                cv_neg_fmeasure = 0\n",
    "            if cv_neut_precision is None:\n",
    "                cv_neut_precision = 0\n",
    "            if cv_neut_recall is None:\n",
    "                cv_neut_recall = 0\n",
    "            if cv_neut_fmeasure is None:\n",
    "                cv_neut_fmeasure = 0\n",
    "\n",
    "                    \n",
    "            accuracy.append(cv_accuracy)\n",
    "            pos_precision.append(cv_pos_precision)\n",
    "            pos_recall.append(cv_pos_recall)\n",
    "            neg_precision.append(cv_neg_precision)\n",
    "            neg_recall.append(cv_neg_recall)\n",
    "            pos_fmeasure.append(cv_pos_fmeasure)\n",
    "            neg_fmeasure.append(cv_neg_fmeasure)\n",
    "            neut_precision.append(cv_neut_precision)\n",
    "            neut_recall.append(cv_neut_recall)\n",
    "            neut_fmeasure.append(cv_neut_fmeasure)\n",
    "            \n",
    "            cv_count += 1\n",
    "        \n",
    "                \n",
    "        print ('---------------------------------------')\n",
    "        print ('N-FOLD CROSS VALIDATION RESULT ' + '(' + classifierName + ')')\n",
    "        print ('---------------------------------------')\n",
    "        print ('accuracy:', sum(accuracy) / n)\n",
    "        print ('precision', (sum(pos_precision)/n + sum(neg_precision)/n + sum(neut_precision)/n) / 3)\n",
    "        print ('recall', (sum(pos_recall)/n + sum(neg_recall)/n + sum(neut_recall)/n) / 3)\n",
    "        print ('f-measure', (sum(pos_fmeasure)/n + sum(neg_fmeasure)/n + sum(neut_fmeasure)/n) / 3)\n",
    "        print ('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(word_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
